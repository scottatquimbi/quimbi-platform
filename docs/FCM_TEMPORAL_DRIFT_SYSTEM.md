# Fuzzy C-Means + Temporal Drift: Complete System Architecture

**Date**: 2025-12-18
**Status**: üîß IMPLEMENTATION IN PROGRESS
**Purpose**: Enable behavioral thumbprint tracking and drift detection

---

## Executive Summary

The clustering system uses **Fuzzy C-Means (FCM)** to create behavioral "thumbprints" - unique fuzzy membership signatures for each customer across 14 behavioral axes. These thumbprints are stored as temporal snapshots, enabling drift analysis to detect customers transitioning between segments (e.g., hobbyist ‚Üí power user, active ‚Üí churning).

**Key Insight**: Hard K-Means cannot track gradual transitions. FCM's soft memberships enable detection of behavioral changes **while they're happening**, not after they complete.

---

## The Problem We're Solving

### Current State (K-Means Hard Clustering)

**Discovery**: 2 segments on purchase_frequency axis
- 94% one-time buyers (churned)
- 6% repeat customers (all lumped together)

**Hidden sub-segments within the 6%**:
1. **Occasional Repeat** (58.2%): 3.8 orders/month, median 154 orders
2. **Active Hobbyists** (18.4%): 1.4 orders/month, median 76 orders
3. **Super-Engaged** (23.0%): 10.8 orders/month, median 297 orders
4. **Enterprise Buyers** (0.4%): 96 orders/month, up to 2,496 orders!

**Problem**: K-Means forces hard boundaries. A customer buying 6 orders/month gets assigned to either "Active Hobbyist" OR "Super-Engaged" (100% or 0%), missing that they're **transitioning** between the two.

---

## The Solution: FCM + Temporal Thumbprints

### 1. Fuzzy C-Means Clustering

**What it does**:
- Assigns **soft (fuzzy) membership** to ALL segments
- Each customer has partial membership in multiple segments
- Memberships sum to 1.0 across segments

**Example**:
```python
# Customer buying 6 orders/month
# K-Means (Hard):
segment = "active_hobbyist"  # 100% or 0%, binary

# Fuzzy C-Means (Soft):
fuzzy_memberships = {
    "occasional": 0.10,
    "active_hobbyist": 0.30,
    "super_engaged": 0.55,  # Dominant (transitioning UP!)
    "enterprise": 0.05
}
```

**Interpretation**: Customer is 55% "Super-Engaged" but still 30% "Active Hobbyist" - they're **upgrading**!

---

### 2. Behavioral Thumbprint

A customer's **thumbprint** = their fuzzy membership vector across all 14 axes at a point in time.

**Structure**:
```python
{
    "customer_id": 12345,
    "snapshot_date": "2025-01-15",
    "snapshot_type": "weekly",

    # Fuzzy memberships (THE THUMBPRINT)
    "fuzzy_memberships": {
        "purchase_frequency": {
            "occasional": 0.10,
            "active_hobbyist": 0.30,
            "super_engaged": 0.55,
            "enterprise": 0.05
        },
        "purchase_value": {
            "budget": 0.20,
            "moderate": 0.65,
            "high_value": 0.15
        },
        "category_exploration": {
            "specialist": 0.70,
            "explorer": 0.25,
            "generalist": 0.05
        },
        # ... 11 more axes (14 total)
    },

    # Hard labels (dominant segment per axis)
    "dominant_segments": {
        "purchase_frequency": "super_engaged",
        "purchase_value": "moderate",
        "category_exploration": "specialist"
    },

    # ML predictions at this point in time
    "churn_risk_score": 0.15,
    "predicted_ltv": 2500.00,

    # Context
    "orders_at_snapshot": 47,
    "total_value_at_snapshot": 1850.00
}
```

This thumbprint is stored in `temporal_snapshots` table.

---

### 3. Temporal Drift Analysis

**How it works**:
1. Take two snapshots (e.g., Week 1 and Week 5)
2. Calculate Euclidean distance in fuzzy membership space
3. Detect transitions, velocity, and severity

**Formula** (from `drift_analysis_service.py:182`):
```python
# For each axis:
drift_score = sqrt(Œ£ (membership_new[seg] - membership_old[seg])¬≤) / sqrt(2)

# Normalized to [0, 1]:
# 0.0 = no drift (identical)
# 1.0 = maximum drift (complete opposite)
```

**Example Calculation**:
```python
# Week 1 (purchase_frequency axis):
old_memberships = {
    "active_hobbyist": 0.70,
    "super_engaged": 0.25,
    "occasional": 0.05
}

# Week 5:
new_memberships = {
    "active_hobbyist": 0.35,  # Declining
    "super_engaged": 0.60,    # Growing! (now dominant)
    "occasional": 0.05
}

# Calculate drift:
drift = sqrt((0.35-0.70)¬≤ + (0.60-0.25)¬≤ + (0.05-0.05)¬≤) / sqrt(2)
     = sqrt(0.1225 + 0.1225 + 0) / 1.414
     = sqrt(0.245) / 1.414
     = 0.350  # "MODERATE" drift

# Interpretation: Customer transitioning from "Active Hobbyist" ‚Üí "Super-Engaged"
```

---

### 4. Drift Severity Levels

```python
drift < 0.1:   "STABLE"       # Customer unchanged
drift 0.1-0.3: "MINOR"        # Slight shift
drift 0.3-0.5: "MODERATE"     # Transitioning (actionable!)
drift 0.5-0.7: "SIGNIFICANT"  # Major behavior change
drift > 0.7:   "MAJOR"        # Complete transformation
```

**Drift Velocity**: Rate of change per day
```python
velocity = drift_score / days_elapsed

# Example:
# 0.35 drift over 28 days = 0.0125 drift/day
# At this rate, full transition in ~80 days
```

---

## Real-World Use Cases

### Use Case 1: Catching Upgrading Customers Mid-Transition

**Scenario**: Hobbyist starting to order more frequently

```python
# Month 1:
fuzzy_memberships = {
    "active_hobbyist": 0.75,      # Dominant
    "super_engaged": 0.20,
    "occasional": 0.05
}

# Month 2:
fuzzy_memberships = {
    "active_hobbyist": 0.50,      # Declining
    "super_engaged": 0.45,        # Rising! üéØ
    "occasional": 0.05
}

# Drift Analysis:
# - Drift score: 0.354 (MODERATE)
# - Direction: Upgrading toward "super_engaged"
# - Action: Send "power user" welcome campaign to accelerate transition
```

**Business Value**: Capture upgrading customers **before** they fully transition, accelerating their journey to higher-value segment.

---

### Use Case 2: Early Churn Detection

**Scenario**: Active customer starting to disengage

```python
# Month 1:
fuzzy_memberships = {
    "super_engaged": 0.80,        # Highly active
    "active_hobbyist": 0.15,
    "churning": 0.05
}

# Month 2:
fuzzy_memberships = {
    "super_engaged": 0.45,        # ‚ö†Ô∏è Declining rapidly
    "active_hobbyist": 0.35,
    "churning": 0.20              # üö® 4x increase!
}

# Drift Analysis:
# - Drift score: 0.495 (MODERATE, near SIGNIFICANT)
# - Churn risk delta: +0.15 (15% increase)
# - Action: Trigger win-back campaign immediately
```

**Business Value**: Detect churn **2-3 months earlier** than traditional "hasn't purchased in 90 days" rules.

---

### Use Case 3: Identifying Hybrid Personas

**Scenario**: Small quilting business (professional frequency, hobbyist spend)

```python
fuzzy_memberships = {
    "purchase_frequency": {
        "enterprise": 0.60,           # Frequent (monthly purchases)
        "super_engaged": 0.30,
        "active_hobbyist": 0.10
    },
    "purchase_value": {
        "moderate": 0.70,             # But moderate $$ per order
        "budget": 0.20,
        "high_value": 0.10
    },
    "category_exploration": {
        "specialist": 0.85,           # Narrow focus (quilting supplies only)
        "explorer": 0.15
    }
}

# Interpretation: Small professional quilting business
# - Buys frequently (monthly)
# - Moderate spend per order (~$50-100)
# - Focused on specific quilting supplies
```

**Business Value**: Identify hybrid personas that don't fit clean K-Means boundaries. Tailor B2B outreach for small professional shops.

---

## Architecture Components

### 1. Fuzzy C-Means Clustering Engine

**File**: [backend/segmentation/fuzzy_cmeans_clustering.py](backend/segmentation/fuzzy_cmeans_clustering.py)

**Key Algorithm**:
```python
# 1. Initialize random fuzzy memberships (rows sum to 1.0)
u = random_fuzzy_memberships(n_customers, n_clusters)

# 2. Iterate until convergence:
for iteration in range(max_iter):
    # Calculate cluster centers (weighted by fuzzy memberships)
    centers = calculate_weighted_centers(X, u, m=2.0)

    # Calculate distances to centers
    distances = euclidean_distances(X, centers)

    # Update fuzzy memberships based on distances
    u = update_fuzzy_memberships(distances, m=2.0)

    # Check convergence
    if norm(u - u_old) < threshold:
        break

# 3. Return:
# - cluster_centers: (k, n_features) array
# - u: (n_customers, k) fuzzy membership matrix
# - labels: argmax(u, axis=1) for hard labels
```

**Fuzziness Parameter (m)**:
- `m = 1.0`: Hard K-Means (binary membership)
- `m = 2.0`: Moderate fuzziness (recommended, default)
- `m = 3.0+`: Very fuzzy (blurred boundaries)

**Configuration**:
```python
FCMConfig(
    m=2.0,                          # Fuzziness
    min_k=3,
    max_k=7,
    min_silhouette=0.30,
    max_dominant_segment_pct=55.0,  # More lenient than K-Means (50%)
    enable_robust_scaling=True,     # Handle outliers
    winsorize_percentile=99.0
)
```

---

### 2. Snapshot Service

**File**: [backend/services/snapshot_service.py](backend/services/snapshot_service.py)

**Purpose**: Create, store, and retrieve temporal customer snapshots

**Snapshot Types & Retention**:
```python
DAILY:     Retain 7 days      # High-frequency monitoring
WEEKLY:    Retain 60 days     # Standard drift tracking
MONTHLY:   Retain 1 year      # Trend analysis
QUARTERLY: Retain 2 years     # Seasonal patterns
YEARLY:    Retain 5 years     # Long-term evolution
```

**Database Schema**:
```sql
CREATE TABLE temporal_snapshots (
    snapshot_id UUID PRIMARY KEY,
    customer_id BIGINT NOT NULL,
    store_id VARCHAR(255) NOT NULL,
    snapshot_date DATE NOT NULL,
    snapshot_type VARCHAR(20) NOT NULL,

    -- Profile data
    archetype_id UUID,
    archetype_level INT,
    archetype_name VARCHAR(255),
    dominant_segments JSONB,      -- {axis: segment_name}
    fuzzy_memberships JSONB,      -- {axis: {segment: score}} üéØ THE THUMBPRINT
    behavioral_features JSONB,    -- Raw features per axis

    -- ML predictions
    churn_risk_score FLOAT,
    churn_risk_level VARCHAR(20),
    predicted_ltv FLOAT,

    -- Context
    orders_at_snapshot INT,
    total_value_at_snapshot DECIMAL(10,2),
    days_since_first_order INT,
    tenure_months FLOAT,

    created_at TIMESTAMP DEFAULT NOW(),
    data_version VARCHAR(10) DEFAULT 'v1.0',

    UNIQUE(customer_id, snapshot_date, snapshot_type)
);

CREATE INDEX idx_temporal_snapshots_customer ON temporal_snapshots(customer_id, snapshot_date);
CREATE INDEX idx_temporal_snapshots_date ON temporal_snapshots(snapshot_date, snapshot_type);
```

**Key Methods**:
```python
# Create snapshot
snapshot = await snapshot_service.create_snapshot(
    customer_id=12345,
    store_id="lindas_electric_quilters",
    snapshot_type=SnapshotType.WEEKLY
)

# Get snapshot history
snapshots = await snapshot_service.get_snapshot_history(
    customer_id=12345,
    start_date=date(2025, 1, 1),
    end_date=date(2025, 3, 1)
)

# Cleanup old snapshots (automatic)
deleted_count = await snapshot_service.cleanup_old_snapshots()
```

---

### 3. Drift Analysis Service

**File**: [backend/services/drift_analysis_service.py](backend/services/drift_analysis_service.py)

**Purpose**: Analyze behavioral drift between two snapshots

**Key Metrics**:
```python
DriftAnalysis(
    customer_id=12345,
    start_date=date(2025, 1, 1),
    end_date=date(2025, 2, 1),
    days_elapsed=31,

    # Overall metrics
    overall_drift_score=0.350,      # 0.0-1.0
    drift_severity="MODERATE",
    drift_velocity=0.0113,          # Drift per day

    # Per-axis drift
    axis_drifts={
        "purchase_frequency": AxisDrift(
            drift_score=0.350,
            old_dominant_segment="active_hobbyist",
            new_dominant_segment="super_engaged",
            segment_changed=True,
            old_membership={"active_hobbyist": 0.70, "super_engaged": 0.25},
            new_membership={"active_hobbyist": 0.35, "super_engaged": 0.60}
        ),
        # ... other axes
    },

    # Transitions
    segments_changed=["purchase_frequency"],
    transition_count=1,

    # ML prediction changes
    churn_risk_delta=-0.05,  # Improved!
    ltv_delta=+250.00,       # Increased LTV

    # Flags
    is_anomaly=False,
    is_improving=True,       # Lower churn + higher LTV
    is_declining=False
)
```

**Drift Detection Algorithm**:
```python
def _calculate_axis_drifts(
    old_memberships: Dict[str, Dict[str, float]],
    new_memberships: Dict[str, Dict[str, float]]
) -> Dict[str, AxisDrift]:
    """
    Calculate Euclidean distance in fuzzy membership space.

    For each axis:
    1. Get all segments in axis
    2. Calculate distance: sqrt(Œ£ (new[seg] - old[seg])¬≤)
    3. Normalize by sqrt(2) to get [0, 1] range
    4. Detect if dominant segment changed
    """

    for axis in all_axes:
        old = old_memberships[axis]  # {seg_a: 0.7, seg_b: 0.3}
        new = new_memberships[axis]  # {seg_a: 0.4, seg_b: 0.6}

        # Euclidean distance
        distance_squared = sum(
            (new.get(seg, 0) - old.get(seg, 0)) ** 2
            for seg in all_segments
        )

        # Normalize to [0, 1]
        drift_score = min(sqrt(distance_squared) / sqrt(2), 1.0)

        # Find dominant segments
        old_dominant = max(old, key=old.get)
        new_dominant = max(new, key=new.get)

        yield AxisDrift(
            axis_name=axis,
            drift_score=drift_score,
            old_dominant_segment=old_dominant,
            new_dominant_segment=new_dominant,
            segment_changed=(old_dominant != new_dominant),
            old_membership=old,
            new_membership=new
        )
```

---

### 4. API Endpoints

**File**: [backend/api/routers/drift_analysis.py](backend/api/routers/drift_analysis.py)

**Endpoints**:

```python
# Get customer snapshot history
GET /drift_analysis/customer/{customer_id}/history
Query params:
  - start_date: YYYY-MM-DD
  - end_date: YYYY-MM-DD
  - snapshot_type: daily|weekly|monthly
Response: List[SnapshotResponse]

# Analyze drift between two dates
GET /drift_analysis/customer/{customer_id}/analysis
Query params:
  - start_date: YYYY-MM-DD (default: 30 days ago)
  - end_date: YYYY-MM-DD (default: today)
Response: DriftAnalysisResponse

# Get visual timeline of drift events
GET /drift_analysis/customer/{customer_id}/timeline
Response: Timeline with drift events, segment transitions, ML prediction changes

# Create snapshot manually
POST /drift_analysis/snapshot/create
Body: {customer_id, store_id, snapshot_type}
Response: SnapshotResponse

# Create snapshots for multiple customers (batch)
POST /drift_analysis/snapshot/batch
Body: {customer_ids: [...], store_id, snapshot_type}
Response: BatchSnapshotResponse (success_count, failed_count)

# Cleanup old snapshots
DELETE /drift_analysis/snapshot/cleanup
Response: {deleted_count, retention_policies_applied}

# Health check
GET /drift_analysis/health
Response: {status, snapshots_enabled, oldest_snapshot, total_snapshots}
```

---

## Implementation Plan

### Phase 1: Enable FCM in Clustering Engine ‚úÖ IN PROGRESS

**Tasks**:
1. ‚úÖ Add FCM toggle to EcommerceClusteringEngine
2. ‚úÖ Replace K-Means with FCM when enabled
3. ‚úÖ Store fuzzy memberships in segment results
4. ‚úÖ Test on repeat customers (discover 4 sub-segments)

**Code Changes**:
```python
# In ecommerce_clustering_engine.py
class EcommerceClusteringEngine:
    def __init__(
        self,
        use_fuzzy_cmeans: bool = False,  # NEW
        fuzzy_m: float = 2.0,            # NEW
        # ... existing params
    ):
        self.use_fuzzy_cmeans = use_fuzzy_cmeans
        self.fuzzy_m = fuzzy_m

        if use_fuzzy_cmeans:
            from .fuzzy_cmeans_clustering import FuzzyCMeans
            self.fcm_config = FCMConfig.from_env()

    async def _cluster_axis(self, ...):
        if self.use_fuzzy_cmeans:
            # Use FCM
            fcm = FuzzyCMeans(
                n_clusters=optimal_k,
                m=self.fuzzy_m,
                max_iter=150
            )
            fcm.fit(X_scaled)
            labels = fcm.predict()
            fuzzy_memberships = fcm.u_  # üéØ STORE THIS!
        else:
            # Use K-Means (existing code)
            kmeans = KMeans(...)
            labels = kmeans.fit_predict(X_scaled)
            fuzzy_memberships = None  # Hard clustering
```

---

### Phase 2: Store Fuzzy Memberships in Segments

**Task**: Modify DiscoveredSegment to include fuzzy membership matrix

**Code Changes**:
```python
# In ecommerce_clustering_engine.py
@dataclass
class DiscoveredSegment:
    segment_id: str
    axis_name: str
    segment_name: str
    cluster_center: np.ndarray
    feature_names: List[str]
    scaler_params: Dict[str, List[float]]
    population_percentage: float
    customer_count: int
    interpretation: str
    fuzzy_membership_matrix: Optional[np.ndarray] = None  # NEW: (n_customers, k)
    customer_fuzzy_scores: Optional[Dict[int, float]] = None  # NEW: {customer_id: membership}
```

---

### Phase 3: Enable Temporal Snapshots

**Tasks**:
1. Set environment variable: `ENABLE_TEMPORAL_SNAPSHOTS=true`
2. Run database migration to create `temporal_snapshots` table
3. Test snapshot creation via API
4. Schedule periodic snapshot jobs (cron/Railway)

**Cron Schedule**:
```yaml
# Railway cron jobs (or use scheduler service)
snapshots:
  daily:
    schedule: "0 2 * * *"  # 2 AM daily
    command: "python3 -m backend.jobs.create_daily_snapshots"

  weekly:
    schedule: "0 3 * * 0"  # 3 AM Sunday
    command: "python3 -m backend.jobs.create_weekly_snapshots"

  monthly:
    schedule: "0 4 1 * *"  # 4 AM 1st of month
    command: "python3 -m backend.jobs.create_monthly_snapshots"

  cleanup:
    schedule: "0 5 * * 0"  # 5 AM Sunday
    command: "python3 -m backend.jobs.cleanup_old_snapshots"
```

---

### Phase 4: Drift Analysis Integration

**Tasks**:
1. Test drift analysis API endpoints
2. Create dashboard visualizations for drift
3. Set up alerts for high-drift customers

**Example Alert Rules**:
```python
# Alert: High-value customer drifting toward churn
if customer.ltv > 5000 and drift.drift_severity in ["SIGNIFICANT", "MAJOR"]:
    if "churning" in drift.segments_changed:
        send_alert("HIGH_VALUE_CHURN_RISK", customer_id)

# Alert: Customer upgrading to power user
if drift.old_dominant == "active_hobbyist" and drift.new_dominant == "super_engaged":
    send_campaign("POWER_USER_WELCOME", customer_id)
```

---

## Configuration

**Environment Variables**:
```bash
# FCM Clustering
ENABLE_FUZZY_CMEANS=true
FCM_FUZZINESS=2.0
FCM_MAX_ITER=150

# Temporal Snapshots
ENABLE_TEMPORAL_SNAPSHOTS=true
SNAPSHOT_STORE_FEATURES=true
SNAPSHOT_STORE_ML=true

# Retention Policies
SNAPSHOT_DAILY_RETENTION=7
SNAPSHOT_WEEKLY_RETENTION=60
SNAPSHOT_MONTHLY_RETENTION=365

# Drift Detection
DRIFT_THRESHOLD=0.1           # Minimum drift to consider meaningful
DRIFT_ANOMALY_THRESHOLD=0.5   # Threshold for anomaly flag
```

---

## Success Metrics

### Clustering Quality
- **Before (K-Means)**: 2 segments (94% one-timers, 6% repeaters)
- **After (FCM)**: 5 segments with sub-segmentation of repeaters
- **Segment balance**: Largest segment <60% (vs 94%)

### Drift Detection
- **Early churn detection**: Identify churning customers 60-90 days earlier
- **Upgrade detection**: Catch 80%+ of customers transitioning to higher-value segments
- **Hybrid identification**: Flag 15-20% of customers with hybrid personas

### Business Impact
- **Campaign effectiveness**: +25% conversion on targeted upgrade campaigns
- **Churn prevention**: Reduce churn by 15-20% through early intervention
- **Personalization**: 90%+ of customers have actionable fuzzy memberships

---

## Current Status

**‚úÖ Completed**:
1. Balance-aware k-selection (prioritizes explanatory power over silhouette)
2. Silhouette score storage bug fixed
3. Repeat customer sub-segment analysis (discovered 4 natural groups)

**üîß In Progress**:
1. Implementing FCM into EcommerceClusteringEngine
2. Testing FCM on 500 repeat customers

**‚è≥ Pending**:
1. Database migration for temporal_snapshots table
2. Snapshot creation jobs
3. Drift analysis API testing
4. Dashboard visualization

---

**Last Updated**: 2025-12-18 17:30
**Next Action**: Implement FCM clustering toggle and test on repeat customers
